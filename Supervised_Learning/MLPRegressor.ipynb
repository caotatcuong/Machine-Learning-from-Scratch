{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E8EvBDuWJ8-K"
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Bodn3mQCJ8-P"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q5QLtae7J8-P"
   },
   "source": [
    "# Implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "h5J9s_D1J8-Q"
   },
   "outputs": [],
   "source": [
    "class MLPRegressor:\n",
    "    def __init__(self, hidden_layer_sizes=[10], alpha=0.01, batch=32, max_iter=1000, l2=0.01, random_state=42):\n",
    "        ''' \n",
    "        Class constructor\n",
    "        We use the relu activation.\n",
    "        Parameters\n",
    "        ----------\n",
    "        hidden_layer_sizes: list number of units of each layers\n",
    "        alpha: the learning rate determines how big the step would be on each iteration.\n",
    "        batch: Using batch samples for one times update weight\n",
    "        max_iter: number of times update weight\n",
    "        l2: l2 regularization\n",
    "        '''\n",
    "        self.hidden_layer_sizes = hidden_layer_sizes\n",
    "        self.alpha = alpha\n",
    "        self.batch = batch\n",
    "        self.max_iter = max_iter\n",
    "        self.l2 = l2\n",
    "        self.random_state = random_state\n",
    "        self.Ws = None\n",
    "    \n",
    "    def relu(self, z):\n",
    "        '''\n",
    "        Computes relu function for each element of array x.\n",
    "        '''\n",
    "        a = np.maximum(0,z)\n",
    "        return a\n",
    "    \n",
    "    def gradientRelu(self, As, Ws ,mb_X, delta, i):\n",
    "        '''\n",
    "        Computes gradient vector for relu layer.\n",
    "        '''\n",
    "        temp = delta.copy()\n",
    "        delta = []\n",
    "        grad = []\n",
    "        for j in range(i, 0, -1):\n",
    "            temp = np.dot(temp, self.Ws[j].T)\n",
    "            temp = np.multiply(temp, np.where(As[j]>=0, 1, 0))\n",
    "            temp = temp[:,1:]\n",
    "            delta.append(temp)\n",
    "            grad.append(np.dot(As[j-1].T,temp) / len(As[j-1]))\n",
    "        return delta, grad\n",
    "    \n",
    "    def computeForwardPropagation(self, Ws, X, need_all_layer_outputs):\n",
    "        '''\n",
    "        Computes the outputs of Neural Net by forward propagating X through the network.\n",
    "        '''\n",
    "        num_layers = len(self.Ws)\n",
    "        As = [X]\n",
    "        a_1 = X\n",
    "        for i in range(num_layers - 1):\n",
    "            z = np.dot(a_1, self.Ws[i])  \n",
    "            a = self.relu(z)\n",
    "            a = np.append(np.ones((a.shape[0], 1)), a, axis=1)\n",
    "            As.append(a)\n",
    "            a_1 = a\n",
    "        z_last = np.dot(As[-1], self.Ws[-1])\n",
    "        a_last = z_last\n",
    "        As.append(a_last)\n",
    "        if need_all_layer_outputs:\n",
    "            return As\n",
    "        else:\n",
    "            return As[-1]\n",
    "    \n",
    "    def computeLayerSizes(self, X, Y, hid_layer_sizes):\n",
    "        num_classes = 1\n",
    "        layer_sizes = [X.shape[1]] + hid_layer_sizes + [num_classes]\n",
    "        return layer_sizes\n",
    "    \n",
    "    def initWeight(self, X, Y, layer_sizes):\n",
    "        np.random.seed(self.random_state) \n",
    "        self.Ws = np.array([np.random.randn(layer_sizes[i] + 1 , layer_sizes[i + 1]) / np.sqrt(layer_sizes[i] + 1) \n",
    "              for i in range(len(layer_sizes) - 1)]) \n",
    " \n",
    "    def updateWeights(self, Ws, As, mb_X, mb_Y, alpha):\n",
    "        \n",
    "        #update weights for output layer\n",
    "        num_hidden_layer = len(self.Ws) - 1\n",
    "        delta_last = (As[-1] - mb_Y) / len(mb_X)\n",
    "        grad_last = (As[-2].T @ delta_last)\n",
    "        delta , grad = self.gradientRelu(As, self.Ws , mb_X, delta_last, num_hidden_layer)\n",
    "        self.Ws[-1] -= alpha * (grad_last  + self.l2 * grad_last) / len(mb_X)\n",
    "        \n",
    "        #update weights for hidden layer\n",
    "        grad = grad[::-1]\n",
    "        for i in range(len(delta)):\n",
    "            self.Ws[i] -= alpha * (grad[i] + self.l2 * grad[i]) / len(mb_X)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        '''\n",
    "        Trains MLPRegressor on the dataset (X, y) using mini-batch Gradient Descent.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy array, shape (m, n)\n",
    "        The matrix of inputs\n",
    "        y : numpy array, shape (m, 1) \n",
    "        The vector of outputs.\n",
    "        '''\n",
    "        # Get layer sizes\n",
    "        layer_sizes = self.computeLayerSizes(X, y, self.hidden_layer_sizes)\n",
    "        \n",
    "        # Prepare for training\n",
    "        self.initWeight(X, y, layer_sizes)\n",
    "    \n",
    "        # First column of this matrix is all ones (corresponding to x_0).\n",
    "        X = np.append(np.ones((X.shape[0], 1)), X, axis=1)\n",
    "        m, n = X.shape\n",
    "        \n",
    "        for iter in range(1, self.max_iter + 1):\n",
    "            # mix data \n",
    "            mix_id = np.random.permutation(m)\n",
    "            for i in list(range(0, m, self.batch)):\n",
    "                # Get batch samples\n",
    "                mb_X = X[mix_id[i : i + self.batch]]\n",
    "                mb_Y = y[mix_id[i : i + self.batch]]\n",
    "                \n",
    "                # Compute forward propagation (all layers)\n",
    "                As = self.computeForwardPropagation(self.Ws, mb_X, True)\n",
    "                \n",
    "                # Back propagation, compute each layer's gradient and update its W\n",
    "                self.updateWeights(self.Ws, As, mb_X, mb_Y, self.alpha)             \n",
    "        \n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        Predict using the MLPRegressor model.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy array, shape (m, n)\n",
    "        The matrix of inputs\n",
    "        \n",
    "        Return\n",
    "        ----------\n",
    "        Returns predicted values.\n",
    "        '''\n",
    "        # First column of this matrix is all ones (corresponding to x_0).\n",
    "        X = np.append(np.ones((X.shape[0], 1)), X, axis = 1)    \n",
    "        # Compute training info, save it, and print it\n",
    "        A = self.computeForwardPropagation(self.Ws, X, False)\n",
    "        return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "6TSu_dR6J8-Q"
   },
   "outputs": [],
   "source": [
    "def standardScaler(X):\n",
    "    return (X - np.mean(X)) / np.std(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "m9r4fJfwJ8-R"
   },
   "outputs": [],
   "source": [
    "def r2(y_test, y_pred):\n",
    "    base = np.sum((y_pred - y_test.mean()) ** 2)\n",
    "    mse = np.sum((y_pred - y_test) ** 2)\n",
    "    r2 = 1 - (mse / base)\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i1xp8rqxJ8-R"
   },
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ImNOZoA7J8-R"
   },
   "outputs": [],
   "source": [
    "#Read data\n",
    "data = pd.read_excel('Data/Folds5x2_pp.xlsx').to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "zImdEz7cJ8-R"
   },
   "outputs": [],
   "source": [
    "# Get 200\n",
    "X = data[:1000,:4]\n",
    "y = data[:1000,-1].reshape(-1,1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l3UkWhEsJ8-S",
    "outputId": "75303d4b-e9e6-4202-82f2-1a1317a554a9"
   },
   "outputs": [],
   "source": [
    "# Using 1 hidden layer with 50 units\n",
    "model = MLPRegressor(hidden_layer_sizes=[50], max_iter=3000)\n",
    "\n",
    "X_train = standardScaler(X_train)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "X_test = standardScaler(X_test)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZbCZkthaJ8-S",
    "outputId": "aa21c1e7-034e-4ee7-8ca7-d4b6ec47fc62"
   },
   "outputs": [],
   "source": [
    "# Using 1 hidden layer with 100 units\n",
    "model = MLPRegressor(hidden_layer_sizes=[100], max_iter=3000)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred1 = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Bo9u1cfYJ8-T",
    "outputId": "a46cf105-b4e5-42ef-d7ac-58e016e48c03"
   },
   "outputs": [],
   "source": [
    "# Using 2 hidden layers with (50,50) units\n",
    "model = MLPRegressor(hidden_layer_sizes=[50,50], max_iter=3000)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred2 = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "5W1PwgnrJ8-T",
    "outputId": "43c470a9-b9cf-4aa3-bafc-58e5283f6509"
   },
   "outputs": [],
   "source": [
    "# Using 2 hidden layers with (100,100) units\n",
    "model = MLPRegressor(hidden_layer_sizes=[100,100], max_iter=3000)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred3 = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "XW9kTQBoJ8-T",
    "outputId": "b8407124-19f8-4c16-a072-e7df2450f3d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of using 1 hidden layer with 50 units: 0.8369887992014104\n",
      "Score of using 1 hidden layer with 100 units: 0.8444423459540666\n",
      "Score of using 2 hidden layers with (50,50) units: 0.9016238923927288\n",
      "Score of using 2 hidden layers with (100,100) units: 0.895304705555458\n"
     ]
    }
   ],
   "source": [
    "print('Score of using 1 hidden layer with 50 units:', r2(y_pred, y_test))\n",
    "print('Score of using 1 hidden layer with 100 units:', r2(y_pred1, y_test))\n",
    "print('Score of using 2 hidden layers with (50,50) units:',  r2(y_pred2, y_test))\n",
    "print('Score of using 2 hidden layers with (100,100) units:',  r2(y_pred3, y_test))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "MLPRegressor.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
